# ğŸš€ GuÃ­a de Inicio RÃ¡pido - AI Alcohol

## âš¡ ConfiguraciÃ³n en 5 minutos

### 1. Clonar el repositorio
```bash
git clone https://github.com/tu-usuario/AI_alcohol.git
cd AI_alcohol
```

### 2. Ejecutar configuraciÃ³n automÃ¡tica

#### Linux/macOS:
```bash
./setup_environment.sh
```

#### Windows:
```powershell
.\setup_environment.ps1
```

### 3. Activar el entorno
```bash
# Linux/macOS
./activate_env.sh

# Windows
.\activate_env.ps1
```

### 4. Iniciar Ollama
```bash
# En una nueva terminal
ollama serve
```

### 5. Ejecutar la aplicaciÃ³n
```bash
python main.py
```

## ğŸ¯ Â¿QuÃ© hace el script automÃ¡tico?

âœ… **Detecta tu sistema operativo** (Linux, macOS, Windows)  
âœ… **Verifica Python 3.8+** e instala si es necesario  
âœ… **Detecta GPU NVIDIA** automÃ¡ticamente  
âœ… **Instala CUDA** si hay GPU NVIDIA disponible  
âœ… **Crea entorno virtual** con todas las dependencias  
âœ… **Instala PyTorch** (GPU o CPU segÃºn disponibilidad)  
âœ… **Instala Ollama** y descarga el modelo llama3:8b  
âœ… **Instala FFmpeg** para procesamiento de audio/video  
âœ… **Crea scripts de activaciÃ³n** personalizados  

## ğŸ”§ ConfiguraciÃ³n Manual (Si el script falla)

### Requisitos mÃ­nimos:
- Python 3.8 o superior
- 8GB RAM mÃ­nimo (16GB recomendado)
- 10GB espacio libre en disco
- GPU NVIDIA (opcional, para aceleraciÃ³n)

### InstalaciÃ³n paso a paso:

```bash
# 1. Crear entorno virtual
python3 -m venv env

# 2. Activar entorno
source env/bin/activate  # Linux/macOS
# o
.\env\Scripts\Activate.ps1  # Windows

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 5. Descargar modelo
ollama pull llama3:8b
```

## ğŸ¬ Primer uso

### Procesar un video individual:
1. Abre la aplicaciÃ³n: `python main.py`
2. Haz clic en "Seleccionar Archivo"
3. Elige un video MP4
4. Haz clic en "ğŸ” Ejecutar todo"
5. Espera a que termine el procesamiento
6. Revisa los resultados en la carpeta `data/results/`

### Procesar mÃºltiples videos:
1. Haz clic en "ğŸ“ Procesar Carpeta Completa"
2. Selecciona la carpeta con los videos
3. El script procesarÃ¡ todos automÃ¡ticamente

## ğŸ“Š Ver resultados

Los resultados se guardan en:
- **GrÃ¡ficas**: `data/results/[video_name]/fluidez_[video_name].png`
- **MÃ©tricas**: `data/results/[video_name]/resumen_fluidez_[video_name].json`
- **EstadÃ­sticas**: `data/results/[video_name]/fluidez_[video_name].xlsx`

## ğŸ†˜ SoluciÃ³n rÃ¡pida de problemas

### Error: "Ollama no estÃ¡ corriendo"
```bash
# Terminal 1: Iniciar Ollama
ollama serve

# Terminal 2: Ejecutar aplicaciÃ³n
python main.py
```

### Error: "CUDA no disponible"
```bash
# Verificar GPU
nvidia-smi

# Si no hay GPU, usar CPU automÃ¡ticamente
# El script ya detecta esto automÃ¡ticamente
```

### Error: "FFmpeg no encontrado"
```bash
# Ubuntu/Debian
sudo apt install ffmpeg

# macOS
brew install ffmpeg

# Windows
choco install ffmpeg
```

### Error: "Permisos denegados"
```bash
# Dar permisos de ejecuciÃ³n
chmod +x setup_environment.sh
chmod +x activate_env.sh
```

## ğŸ“ˆ MÃ©tricas que obtienes

Para cada video procesado:
- **PPM Promedio**: Palabras por minuto
- **PPM Final**: Fluidez al final de la prueba
- **DesviaciÃ³n EstÃ¡ndar**: Variabilidad en la fluidez
- **Total de Palabras**: NÃºmero de animales mencionados
- **Tiempo Total**: DuraciÃ³n de la prueba
- **ClasificaciÃ³n SemÃ¡ntica**: AgrupaciÃ³n de animales

## ğŸ¯ Ejemplo de uso completo

```bash
# 1. Configurar todo automÃ¡ticamente
./setup_environment.sh

# 2. Activar entorno
./activate_env.sh

# 3. Iniciar Ollama (nueva terminal)
ollama serve

# 4. Procesar video
python main.py
# - Seleccionar archivo: video_paciente.mp4
# - Ejecutar todo
# - Esperar procesamiento

# 5. Ver resultados
ls data/results/video_paciente/
# - fluidez_video_paciente.png (grÃ¡fica)
# - resumen_fluidez_video_paciente.json (mÃ©tricas)
# - fluidez_video_paciente.xlsx (Excel)
```

## ğŸ” Verificar instalaciÃ³n

```bash
# Verificar Python
python --version

# Verificar PyTorch
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import torch; print(f'CUDA disponible: {torch.cuda.is_available()}')"

# Verificar Ollama
ollama list

# Verificar FFmpeg
ffmpeg -version
```

## ğŸ“ Â¿Necesitas ayuda?

1. **Revisa los logs** en la terminal
2. **Verifica la documentaciÃ³n** en `docs/`
3. **Ejecuta las pruebas**: `python tests/test_basic_functionality.py`
4. **Abre un issue** en GitHub

---

**Â¡Listo! Ya puedes empezar a analizar fluidez verbal con IA.** ğŸ‰ 